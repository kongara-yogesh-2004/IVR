{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loaded :)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader \n",
    "file_path = \"customer.csv\" # Need not change the path if you are forking the Repo\n",
    "loader = CSVLoader(file_path=file_path,encoding=\"utf-8\",metadata_columns=[\"flags\",\"category\",\"intent\",\"response\"])\n",
    "data = loader.load() # Loading the document objects\n",
    "print(\"Documents loaded :)\")\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model....\n",
      "Loaded and up!\n",
      "Embedding starting....\n",
      "Values Embedded!\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings  # Using hugging face embeddings for the embedding model\n",
    "from tqdm import TqdmWarning   # Just using this to ignore warnings from tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=TqdmWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "\n",
    "print(\"Loading embedding model....\")\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "print(\"Loaded and up!\")\n",
    "data_list = [] # A list to store the Page content (Columns: [\"instruction\"])\n",
    "metadata = [] # A list to store the metadata (Columns: [\"flags\",\"category\",\"intent\",\"response\"])\n",
    "count = 0 # A variable for indexing purpose\n",
    "\n",
    "for i in data:\n",
    "    data_list.append(data[count].page_content)\n",
    "    metadata.append(data[count].metadata)\n",
    "    count += 1\n",
    "print(\"Embedding starting....\")\n",
    "embeded_val = embedding.embed_documents(data_list) # Embedding the data_list using the embedding model\n",
    "print(\"Values Embedded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma # Using Chroma DB as our vector database\n",
    "db1 = Chroma.from_texts(texts=data_list,embedding=embedding,metadatas=metadata) # Storing the embedded values to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='instruction: I have a problem updating my delivery address', metadata={'category': 'SHIPPING', 'flags': 'BL', 'intent': 'change_shipping_address', 'response': \"I'm sorry to hear that you're having trouble updating your delivery address. Could you please provide more details about the issue you are experiencing? This will help me assist you better.\", 'row': 2162, 'source': 'customer.csv'}), 0.058140963315963745)\n",
      "(Document(page_content='instruction: I am trying to update my delivery address', metadata={'category': 'SHIPPING', 'flags': 'BL', 'intent': 'change_shipping_address', 'response': 'No worries! Updating your delivery address is a simple process. You can do it by logging into your account on our website and going to the \"Manage Addresses\" section. From there, you can edit your current address or add a new one. If you need any help, feel free to reach out to our customer service team.', 'row': 2845, 'source': 'customer.csv'}), 0.06622816622257233)\n",
      "(Document(page_content='instruction: I have troubles updating my delivery address', metadata={'category': 'SHIPPING', 'flags': 'BLM', 'intent': 'change_shipping_address', 'response': 'We apologize for the difficulties you are experiencing while trying to update your delivery address. Our customer support team is here to assist you. Please provide us with the correct details, and we will ensure that your address is updated accurately in our system.', 'row': 2189, 'source': 'customer.csv'}), 0.07183951884508133)\n",
      "(Document(page_content='instruction: their is a problem trying to update my delivery address', metadata={'category': 'SHIPPING', 'flags': 'BLZ', 'intent': 'change_shipping_address', 'response': \"We apologize for the inconvenience you're facing while trying to update your delivery address. Our team is here to assist you in resolving this problem. Please provide us with the correct address, and we'll make sure it's updated in our system.\", 'row': 2098, 'source': 'customer.csv'}), 0.07651837170124054)\n"
     ]
    }
   ],
   "source": [
    "query = \"i am not able to update my delivery address\"\n",
    "# query = \"I want to cancel my order\"\n",
    "# query = \"what is the cancellation charges for my order?\"\n",
    "# query = \"i want to delete my account\"\n",
    "\n",
    "embedding_vector = embedding.embed_query(\"instruction: \"+query) # Converting the text query into vectors for semantic searching\n",
    "docs_and_scores = db1.similarity_search_by_vector_with_relevance_scores(embedding_vector) # Searching the database for the top 4 documents (default k value is 4)\n",
    "docs_and_scores\n",
    "for i in range(0,4):\n",
    "    print(docs_and_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Response:\n",
      "\n",
      "\"I apologize for the inconvenience, Amazon allows only one active default shipping address. Please ensure there are no duplicate addresses or try updating from Your Account > Shipping Settings. If the issue persists, I'll be happy to further assist you.\""
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\",system=\"You are a efficient customer care agent working at Amazon. Analyze the 'Realtime customer query', 'predefined query' and the 'predefined response' and return a new response for the Customer (keep the responses short (within 30 words) and to the point as it is a call). If the 'Realtime customer query' and the 'predefined query' don't match, reject the query politely\")\n",
    "chunks = llm.stream(input=\"query: \" + docs_and_scores[0][0].page_content[13:] +\" predefined response: \" + docs_and_scores[0][0].metadata['response']) # Here Stream was used so that we don't have to wait for the whole response to be generated from the model\n",
    "for chunk in chunks:\n",
    "    print(chunk,end='',flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
